# Methods

```{r setup2, include = FALSE}
# load R libraries here; the `include` flag in the chunk options above tells
# whether to print the results or not. Usually you don't want to print the
# library statements, or any code on the pdf.

# Main Packages ========
# I use these in every doc
library(tidyverse)
library(knitr)
library(kableExtra)
library(modelsummary)

options(dplyr.summarise.inform = FALSE)

# Other packages ------
# These sometimes get used, and sometimes don't.
library(mlogit)

# Instructions and options =========
# prints missing data in tables as blank space
options(knitr.kable.NA = '') 
# tells kableExtra to not load latex table packages in the chunk output
options(kableExtra.latex.load_packages = FALSE) 
options(modelsummary_format_numeric_latex = "plain")

# round and format numbers that get printed in the text of the article.
inline_hook <- function(x) {
  if (is.numeric(x)) {
    format(x, digits = 3, big.mark = ",")
  } else x
}
knitr::knit_hooks$set(inline = inline_hook)

knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

# options for latex-only output
if(knitr::is_latex_output()) {
  knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
} 

```

## Data

The GPS data used to determine the four most accurate parameters come from 60 volunteers in
the Utah County area and were taken over a period of six or more months depending on the person. An example of what the raw GPS data looked like is shown in Figure 2.1.

```{r Figure1, echo=FALSE, message=FALSE, warning=FALSE}
rawData <- read_csv("data/Health Study_5f5184e73e2fd848eac22aec_passivelocation_57.csv")

rawData <- head(rawData)

rawData1 <- rawData %>%
  select(accuracy, timestamp, speed, lat,lon, time)

rawData1 %>%
kbl(booktabs = T, caption = "Raw GPS Data", longtable = T) %>%
  kable_styling(full_width = F)

```

Before the GPS data can be processed, it had to be cleaned and reformatted. Since a DBSCAN algorithm is being used, the speed variable was removed completely. From there, the dates and times had to be reformatted using functions from the **lubridate** package in R and by writing a "Yesterday" function with output "ActivityDay" that defines activity days as being from 3 AM to 3 AM instead of 12 AM to 12 AM. This was done because many respondents are college students, so they are likely to make trips after midnight. Table 2.2 shows what the cleaned data looked like.

```{r Figure2, echo=FALSE, message=FALSE, warning=FALSE}
source("R/gps2trips.R")

cleaned_data <- makeCaps("data") %>%
  select(lat,lon,timestamp,date,time,activityDay)
cleaned_data <- head(cleaned_data)

cleaned_data %>%
kbl(booktabs = T, caption = "Cleaned GPS Data", longtable = T) %>%
  kable_styling(full_width = F)

```


## Models

Once the data is cleaned and properly formatted, it is run through a DBSCAN-entropy hybrid algorithm largely based on the method created by Gong et al. in 2018 [@GongInspiration]. After the DBSCAN algorithm determines how many total clusters there are based on the eps and minpts parameters, they get further split based on the delta_t parameter if necessary. If the time difference between points at the same place is greater than delta_t, then the points will be split into two separate clusters or activities. 

Finally, there is an entropy calculation step where entropy is determined by the change in departure angle between consecutive points. The equation for this entropy is shown in the equation below [@GongInspiration]. If the points are in a line, the entropy is very low. In this algorithm, the entr_t parameter determines at which entropy someone is actually likely to be moving and not just at a stoplight, etc.

\begin{equation}
  EI_q = -\sum_{d=1}^D ((\frac{n_d}{N})ln(\frac{n_d}{N}))
\end{equation}

For this experiment, I will look at a map of the unprocessed, cleaned data and determine with my eyes how many clusters there are. Then, the hybrid algorithm will calculate the number of clusters using randomized values for the four parameters. Based on all the previous research that has been discussed, the ranges for the possible parameters are as follows:

minpts: (3,10)
eps: (1,50)
delta_t: (300, 1500) seconds
entr_t: (0.5,3)

Then, I will compare the amount of clusters I saw to the number of clusters the hybrid algorithm calculated. This process was repeated 5 times over 10 different days in order to determine which parameters are the most accurate.

