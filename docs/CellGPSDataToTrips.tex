\documentclass[3p, authoryear]{elsarticle} %review=doublespace preprint=single 5p=2 column
%%% Begin My package additions %%%%%%%%%%%%%%%%%%%
\usepackage[hyphens]{url}

  \journal{Submitted to Journal} % Sets Journal name


\usepackage{lineno} % add
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\usepackage{graphicx}
%%%%%%%%%%%%%%%% end my additions to header

\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \usepackage{fontspec}
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{â‚¬}
\fi
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}
\usepackage{natbib}
\bibliographystyle{apalike}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={Determining DBSCAN-Entrpopy Hybrid Algorithm Parameters for Converting GPS Points to Activities},
            colorlinks=false,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

\setcounter{secnumdepth}{5}
% Pandoc toggle for numbering sections (defaults to be off)

% Pandoc citation processing

% Pandoc header
\usepackage{booktabs}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}



\begin{document}
\begin{frontmatter}

  \title{Determining DBSCAN-Entrpopy Hybrid Algorithm Parameters for Converting GPS Points to Activities}
    \author[Brigham Young University]{Gillian Riches\corref{1}}
   \ead{martingillian4@gmail.com} 
    \author[Brigham Young University]{Gregory Macfarlane\corref{2}}
   \ead{gregmacfarlane@byu.edu} 
      \address[Brigham Young University]{Civil and Environmental Engineering Department, 232 Engineering Building, Provo, Utah 84602}
      \cortext[1]{Corresponding Author}
    \cortext[2]{Present affiliation: Committee Chair}
  
  \begin{abstract}
  DBSCAN Entropy algorithms appear to be the most accurate way to process the GPS data into trips/activities. This algorithm takes
  four parameters to work: minimum number of points (minpts), radius for those points (eps), entropy threshold (entr\_t),
  and a time difference threshold (delta\_t). While there are lots of studies that explain ways to
  determine minpts, eps, and entr\_t, information lacks deciding on
  an accurate delta\_t parameter. This paper explains one method of how to choose an adequate delta\_t parameter: implement a DBSCAN Entropy algorithm in R alongside raw GPS data maps to use for comparison.
  \end{abstract}
   \begin{keyword} GPS Data, Trips, DBSCAN, parameters\end{keyword}
 \end{frontmatter}

\hypertarget{question}{%
\section{Question}\label{question}}

Global Positioning System (GPS) surveys have become a more accurate and reputable alternative to previous travel survey methods that collect activity-travel patterns. Despite GPS devices' ability to record time and positional characteristics, further processing is required to determine the number of trips.

A DBSCAN algorithm (Density-Based Spatial Clustering of Applications with Noise) is one of the most accurate ways to process GPS data because it ``overcome{[}s{]} some inherent limitations of partitioning and hierarchical algorithms''\citep{DBSCANWeb2019}. In fact, one experiment \citep{DBAlgorithm2017} using just a DBSCAN cluster-based algorithms proved to be 92\% precise which is significantly better than the typical 43\% to 61\% reported from using rule-based algorithms \citep{reviewOfMethods2014}.

If one wishes to remove error even further, entropy (the chaotic movement betwen points in a cluster) can be added to the DBSCAN algorithm as done by Gong et al.~in 2018 (\citep{GongInspiration}). Including entropy removes inaccuracies that come from situations like a stoplight being mistaken as its own trip.

For a DBSCAN-Entropy Algorithm to work, four parameters are required: minimum number of points to be considered a cluster (minpts), radius in which those minpts can occur in (eps), the entropy threshold (entr\_t), and the time threshold in which one trip is considered two trips at the same location (delta\_t).

One common way to select the minpts and radius (eps) thresholds is to arbitrarily pick the minpts based on how large the data set is (with a minimum of three) and then set k = minPts in a k-distance plot \citep{RKNNMethod2018} to find eps. Unfortunately, this method only works in a pure DBSCAN algorithm where only minpts and eps are accounted for, not entr\_t and delta\_t. Gong et al.~(2018) was able to determine an accurate entr\_t threshold: . However, delta\_t is still arbitrarily chosen and not as much research or experiments have been done to determine an accurate delta\_t.

Hence, the purpose of this paper is to explore a method of how to select an accurate delta\_t parameter to use in a DBSCAN-Entropy Algorithm while keeping the other three parameters constant.

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{data}{%
\subsection{Data}\label{data}}

The GPS data used to determine the most accurate delta\_t parameter came from one volunteer in
the Utah County area and was taken over a period of six months. For the purposes of this question, only 10 days worth of GPS data will be processed.

\hypertarget{models}{%
\subsection{Models}\label{models}}

Ultimately, to choose the most accurate delta\_t parameter, the number of clusters calculated by the algorithm (algorithm clusters) was compared to the number of clusters it appeared there should be for that day (manual clusters). The method for how those clusters were created are described below.

\hypertarget{algorithm-clusters}{%
\subsubsection{Algorithm Clusters}\label{algorithm-clusters}}

Once the data was cleaned and properly formatted, it was run through a DBSCAN-entropy hybrid algorithm largely based on the method created by Gong et al.~in 2018 \citep{GongInspiration}. The concepts from Gong's DBSCAN-Entropy algorithm were taken and written in R using the \emph{dbscan} package \citep{dbscanR} and a new \emph{gpsactivs} package written by Dr.~Gregory Macfarlane that has yet to be published to CRAN for public use.

For this algorithm, the four parameters of minpts, eps, entr\_t, delta\_t are required. Based on the current literature, the three constant parameters were set as follows:

\begin{itemize}
\item
  mintpts = 3
\item
  eps = 25 meters
\item
  entr\_t = 1.0
\end{itemize}

To compare the accuracies of different delta\_t parameters, 20 draws were done for each of the 10 days. Each draw kept the same constant parameters as listed above, and the delta\_t parameter was randomly selected from a range of 1 to 400 seconds. By the end of running this algorithm, each of the 10 days had 20 outputs for the number of clusters as determined by the randomly selected delta\_t parameter.

\hypertarget{manual-clusters}{%
\subsubsection{Manual Clusters}\label{manual-clusters}}

To get the number of ``manual clusters'' per day, maps of the raw GPS data were created using the \emph{sf} package in R \citep{sfR}. Those maps were then referenced as the researchers made their own GeoJSON files that stored the geometric locations of where potential trips looked like they were happening. One GeoJSON file was created for each day.

Finally those GeoJSON files were read into R and appended onto the table including the algorithm's calculated number of clusters. For each of the 10 days, the 20 algorithm possibilities for number of clusters was compared to the number of manual clusters picked in the GeoJSON files. From this, the percent error was calculated and the delta\_t parameter that consistently gave the lowest error across all 10 days was deemed to be the most accurate delta\_t parameter to use in this DBSCAN-Entropy Algorithm.

\hypertarget{findings}{%
\section{Findings}\label{findings}}

The error between the two numbers of clusters per day was calculated by taking the
difference in algorithm clusters and manual clusters. Then, the percent error was
found by dividing the integer error by the number of manual clusters, since
that was treated as the ``goal'' for the algorithm to match. The percent error is
indicated by the ``pctError'' column.

\begin{verbatim}
##    eps minpts  delta_t entr_t       date    manual  clusters error  pctError
## 1:  40     20 29.18139      1 2020-02-16 <sf[3x2]> <sf[1x6]>     2 0.6666667
## 2:  40     20 29.18139      1 2020-02-17 <sf[3x2]> <sf[2x6]>     1 0.3333333
## 3:  40     20 29.18139      1 2020-04-15 <sf[4x2]> <sf[2x6]>     2       0.5
## 4:  40     20 29.18139      1 2020-04-16 <sf[6x2]> <sf[6x6]>     0         0
## 5:  40     20 29.18139      1 2020-04-17 <sf[5x2]> <sf[2x6]>     3       0.6
## 6:  40     20 29.18139      1 2020-05-14 <sf[5x2]> <sf[1x6]>     4       0.8
\end{verbatim}

Figure 3.1 visualizes the percent error between algorithm clusters and manual clusters
for all 10 dates. The black line represents the overall trend line.

\label{fig:showErrorPlot}delta\_t versus percent error by date

Most of the dates appear to follow the same trend with a decrease in error when delta\_t
is equal to 10.78 seconds. However, this is when the error is the largest for February 17th and
May 27th, so is not the best option. The percent error is close to 0 for all dates when delta\_t
is equal to 106.3 seconds and 144.7 seconds because delta\_t defines how long the minpts must
be in eps radius for something to count as a trip. It is a lot more likely that a trip/activity
is occurring if someone stays put for over a minute than only 10 seconds. For example,
someone could be at a red light for 10 seconds, but that should not count as its own separate trip.
Having delta\_t be closer to 100 seconds removes potential error from situations such as that.

The trend line also shows that the larger delta\_t gets, the larger the percent error gets. However, this is likely due
to the outliers of February 17th and May 27th. Without those dates, the trend line would likely not start as low. It is
also important to consider the possible gaps in this analysis: falsely identifying manual clusters in the GeoJSON software and
the constant parameters. Manual clusters would be more accurate if confirmed by the respondent via a journal. Also,
the algorithm would potentially predict a different number of clusters for each delta\_t if the three
constant parameters were different. Therefore, more rounds of this study should be conducted to confirm these results. Further applications of this method should be done with more dates, confirmed correct manual clusters, more than 20 draws for delta\_t, and different options for the constant parameters.

\hypertarget{acknowledgements}{%
\section*{Acknowledgements}\label{acknowledgements}}
\addcontentsline{toc}{section}{Acknowledgements}

\hypertarget{references}{%
\section*{References}\label{references}}
\addcontentsline{toc}{section}{References}

\bibliography{book.bib}


\end{document}
