[["question.html", "Determining DBSCAN-Entrpopy Hybrid Algorithm Parameters for Converting GPS Points to Activities 1 Question", " Determining DBSCAN-Entrpopy Hybrid Algorithm Parameters for Converting GPS Points to Activities Gillian Riches Brigham Young University martingillian4@gmail.com Gregory Macfarlane Brigham Young University gregmacfarlane@byu.edu 2021-11-18 Abstract This is where the abstract should go. 1 Question Global Positioning System (GPS) surveys have become a more accurate and reputable alternative to previous travel survey methods that collect activity-travel patterns. Despite GPS devices ability to record time and positional characteristics, they still require two steps, cleaning and processing, in order to convert the positional characteristics into trip purposes and activities. Currently, many researchers use time and speed rule-based algorithms to define when and where activities occur (Shen and Stopher 2014). Due to their subjective nature, these rules are not ideal. For example, people walk at different speeds, so the speed threshold at which someone is considered stagnant would require manual changing from person to person. If not changed, the number of activities for each person could be misleading and inaccurate. These issues may explain why rule-based algorithms accuracies typically range from 43% to 61% (Shen and Stopher 2014). While these processing results (Step 2) are not ideal, the data-cleaning method (Step 1) still serves as a reputable guide regardless of the processing method. Therefore, once the data is cleaned with accordance to rule-based algorithm methods, a DBSCAN and entropy based algorithm should be applied for the processing step. In this type of algorithm, four parameters are needed to determine an activity: minimum number of points (minpts) within a predefined radius (eps) with a minimum amount of entropy (entr_t) (Gong L. 2018), and after a certain period of time from the previous activity (delta_t) . When selected properly, these parameters will not need to change from person to person and therefore often lead to more accurate activity counts. In fact, one experiment (Luo et al. 2017) using just a DBSCAN cluster-based algorithms proved to be 92% precise. One way to select the minPoints and radius (eps) thresholds is to arbitrarily pick the minPoints based on how large the data set is (with a minimum of three) and then set k = minPts in a k-distance plot (Kassambara 2018). Good values of the radius value is where the k-distance plot shows a strong bend. Another method involves calculating the arithmetic mean and standard deviation of a synthetic GPS trajectory, and subject those values to a Gaussian curve equation to solve for eps given an arbitrary minPts (Xiu-Li and Wei-Xiang 2009). Unfortunately, these methods only work in a pure DBSCAN algorithm where only minpts and eps are accounted for, not entr_t and delta_t. Hence, the purpose of this paper is to explore a method of how to simultaneously select all four parameters as accurately as possible in a DBSCAN entropy based algorithm after the GPS data has been cleaned. References "],["methods.html", " 2 Methods 2.1 Data 2.2 Models", " 2 Methods 2.1 Data The GPS data used to determine the four most accurate parameters come from 60 volunteers in the Utah County area and were taken over a period of six or more months depending on the person. An example of what the raw GPS data looked like is shown in Figure 2.1. Table 2.1: Raw GPS Data accuracy timestamp speed lat lon time 16 2021-03-17 22:59:36 -1 40.25293 -111.6602 1.616044e+12 16 2021-03-17 22:59:37 -1 40.25293 -111.6602 1.616044e+12 16 2021-03-17 22:59:38 -1 40.25293 -111.6602 1.616044e+12 16 2021-03-17 22:59:39 -1 40.25293 -111.6602 1.616044e+12 16 2021-03-17 22:59:40 -1 40.25293 -111.6602 1.616044e+12 16 2021-03-17 22:59:41 -1 40.25293 -111.6602 1.616044e+12 Before the GPS data can be processed, it had to be cleaned and reformatted. Since a DBSCAN algorithm is being used, the speed variable was removed completely. From there, the dates and times had to be reformatted using functions from the lubridate package in R and by writing a Yesterday function with output ActivityDay that defines activity days as being from 3 AM to 3 AM instead of 12 AM to 12 AM. This was done because many respondents are college students, so they are likely to make trips after midnight. Table 2.2 shows what the cleaned data looked like. Table 2.2: Cleaned GPS Data lat lon timestamp date time activityDay 40.25293 -111.6602 2021-03-17 22:59:36 2021-03-17 22:59:36 17-3 40.25293 -111.6602 2021-03-17 22:59:37 2021-03-17 22:59:37 17-3 40.25293 -111.6602 2021-03-17 22:59:38 2021-03-17 22:59:38 17-3 40.25293 -111.6602 2021-03-17 22:59:39 2021-03-17 22:59:39 17-3 40.25293 -111.6602 2021-03-17 22:59:40 2021-03-17 22:59:40 17-3 40.25293 -111.6602 2021-03-17 22:59:41 2021-03-17 22:59:41 17-3 2.2 Models Once the data is cleaned and properly formatted, it is run through a DBSCAN-entropy hybrid algorithm largely based on the method created by Gong et al. in 2018 (Gong L. 2018). After the DBSCAN algorithm determines how many total clusters there are based on the eps and minpts parameters, they get further split based on the delta_t parameter if necessary. If the time difference between points at the same place is greater than delta_t, then the points will be split into two separate clusters or activities. Finally, there is an entropy calculation step where entropy is determined by the change in departure angle between consecutive points. The equation for this entropy is shown in the equation below (Gong L. 2018). If the points are in a line, the entropy is very low. In this algorithm, the entr_t parameter determines at which entropy someone is actually likely to be moving and not just at a stoplight, etc. \\[\\begin{equation} EI_q = -\\sum_{d=1}^D ((\\frac{n_d}{N})ln(\\frac{n_d}{N})) \\end{equation}\\] For this experiment, I will look at a map of the unprocessed, cleaned data and determine with my eyes how many clusters there are. Then, the hybrid algorithm will calculate the number of clusters using randomized values for the four parameters. Based on all the previous research that has been discussed, the ranges for the possible parameters are as follows: minpts: (3,10) eps: (1,50) delta_t: (300, 1500) seconds entr_t: (0.5,3) Then, I will compare the amount of clusters I saw to the number of clusters the hybrid algorithm calculated. This process was repeated 5 times over 10 different days in order to determine which parameters are the most accurate. References "],["findings.html", " 3 Findings 3.1 Additional Analysis", " 3 Findings This section might be called Results instead of Applications, depending on what it is that you are working on. But youll probably say something like The initial model estimation results are given in Table ??. That table is created with the modelsummary() package and function. model1 &lt;- mlogit(choice ~ type + price | -1, data = car_mlogit) model2 &lt;- update(model1, .~. + range) models &lt;- list(&quot;Model 1&quot; = model1, &quot;Model 2&quot; = model2) With those results presented, you can go into a discussion of what they mean. first, discuss the actual results that are shown in the table, and then any interesting or unintuitive observations. 3.1 Additional Analysis Usually, it is good to use your model for something. Hypothetical policy analysis Statistical validation effort Equity or impact analysis If the analysis is substantial, it might become its own top-level section. "],["acknowledgements.html", "Acknowledgements", " Acknowledgements "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
